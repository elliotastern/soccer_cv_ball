# Training Configuration for RF-DETR - Optimized for RTX A5000 (24GB VRAM)
# This config maximizes training speed while staying within GPU memory limits

# Model Architecture
model:
  architecture: "detr"  # Options: "detr" (vanilla DETR) or "rfdetr" (RF-DETR from Roboflow)
  backbone: "resnet50"  # ResNet backbone
  num_classes: 2  # player, ball
  pretrained: true  # Use pre-trained weights
  hidden_dim: 256
  nheads: 8
  num_encoder_layers: 6
  num_decoder_layers: 6
  # RF-DETR specific options (used when architecture="rfdetr")
  rfdetr_size: "base"  # Options: "nano", "small", "medium", "base", "large"

# Hyperparameters - Optimized for A5000 (24GB VRAM)
training:
  batch_size: 36  # Increased from 24/32 - A5000 can handle this with mixed precision
  num_epochs: 100
  learning_rate: 0.0001  # 1e-4 as float
  weight_decay: 0.0001  # 1e-4 as float
  warmup_epochs: 5
  gradient_clip: 0.1
  gradient_accumulation_steps: 1  # No accumulation needed with larger batch size
  memory_cleanup_frequency: 30  # Less frequent cleanup = less overhead
  adaptive_optimization: true
  target_gpu_utilization: 0.92  # Push GPU harder (was 0.85-0.90)
  max_ram_usage: 0.90  # Allow more RAM usage
  adaptive_adjustment_interval: 100  # Less frequent checks = less overhead
  mixed_precision: true  # CRITICAL: FP16/FP32 mixed precision (~2x speedup, ~50% memory reduction)
  compile_model: false  # Disabled: causes recompilation overhead with variable-sized DETR inputs
  channels_last: true  # Use channels-last memory format for faster convolutions (~10-15% speedup)
  cudnn_benchmark: true  # Optimize CUDNN for consistent input sizes
  tf32: true  # Enable TF32 on Ampere GPUs (A5000) for faster matmul (~1.5x speedup)
  # Focal Loss configuration for handling class imbalance
  focal_loss:
    enabled: true
    alpha: 0.25  # Weighting factor for rare class (ball)
    gamma: 2.0  # Focusing parameter - higher gamma focuses more on hard examples

# Optimizer
optimizer:
  type: "AdamW"
  lr: 0.0001  # 1e-4 as float
  betas: [0.9, 0.999]
  weight_decay: 0.0001  # 1e-4 as float

# Learning Rate Schedule
lr_schedule:
  type: "cosine"  # cosine annealing
  warmup_epochs: 5
  min_lr: 0.000001  # 1e-6 as float

# Data Augmentation - Reduced for speed
augmentation:
  train:
    horizontal_flip: 0.5
    color_jitter:
      brightness: 0.2
      contrast: 0.2
      saturation: 0.2
      hue: 0.1
    random_crop: false
    resize_range: [800, 1333]  # DETR standard
    # Copy-Paste augmentation for ball class balancing
    copy_paste:
      enabled: true
      prob: 0.5  # Probability of applying copy-paste
      max_pastes: 3  # Maximum balls to paste per image
    # Heavy augmentations disabled for speed
    clahe:
      enabled: false  # Disabled for speed - minimal accuracy impact
      clip_limit: 2.0
      tile_grid_size: [8, 8]
    motion_blur:
      enabled: false  # Disabled for speed - minimal accuracy impact
      prob: 0.3
      max_kernel_size: 15
  val:
    resize: 1333  # Fixed size for validation

# Dataset - Maximized for speed
dataset:
  train_path: "/workspace/datasets/train"
  val_path: "/workspace/datasets/val"
  num_workers: 12  # Increased from 4-8 - more parallel data loading (CPU cores allowing)
  pin_memory: true  # Faster GPU transfer
  prefetch_factor: 6  # Increased from 2-4 - prefetch more batches ahead
  persistent_workers: true  # Enabled: faster worker startup, no worker recreation overhead
  # Note: persistent_workers requires num_workers > 0

# Checkpoint Settings
checkpoint:
  save_dir: "models/checkpoints"
  save_frequency: 999  # Disabled: use lightweight checkpoints only
  save_every_epoch: true  # Save lightweight checkpoint every epoch
  keep_last_lightweight: 10  # Keep fewer checkpoints to save disk space
  save_best: false  # Disabled: use lightweight checkpoints only
  metric: "mAP"
  use_lightweight_only: true  # Only save lightweight checkpoints

# Evaluation - Reduced frequency for speed
evaluation:
  iou_thresholds: [0.5, 0.75]  # IoU thresholds for mAP
  max_detections: 100
  val_frequency: 2  # Validate every 2 epochs instead of every epoch (2x speedup during validation)

# Logging - Reduced I/O for speed
logging:
  log_dir: "logs"
  tensorboard: true
  mlflow: true
  mlflow_tracking_uri: "file:./mlruns"
  mlflow_experiment_name: "detr_training_fast"
  mlflow_log_models: false  # Disabled for speed - model logging is slow
  print_frequency: 100  # Less frequent printing (less I/O overhead)
  log_every_n_steps: 200  # Less frequent TensorBoard logging (less I/O overhead)
